{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa1CiA+UME9QjF+hnQuvTz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshhrawte/Stemming/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Harsh Rawte 22101A0047\n",
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from typing import List, Dict\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "STOP_WORDS = {\n",
        "    'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with',\n",
        "    'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does',\n",
        "    'did', 'will', 'would', 'could', 'should', 'may', 'might', 'can', 'this', 'that',\n",
        "    'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her',\n",
        "    'us', 'them', 'my', 'your', 'his', 'its', 'our', 'their', 'from', 'up', 'about',\n",
        "    'into', 'through', 'during', 'before', 'after', 'above', 'below', 'between', 'among',\n",
        "    'also', 'like', 'such', 'so', 'than', 'too', 'very', 'just', 'now', 'then', 'here',\n",
        "    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
        "    'most', 'other', 'some', 'only', 'own', 'same'\n",
        "}\n",
        "\n",
        "def simple_tokenize(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "    words = text.split()\n",
        "    return [word for word in words if len(word) > 2 and not word.isdigit()]\n",
        "\n",
        "try:\n",
        "    print(\"Attempting to download NLTK data...\\n\")\n",
        "    for resource in [\n",
        "        'punkt', 'stopwords', 'averaged_perceptron_tagger', 'wordnet', 'omw-1.4'\n",
        "    ]:\n",
        "        nltk.download(resource, quiet=True)\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords\n",
        "    from nltk.tag import pos_tag\n",
        "    NLTK_AVAILABLE = True\n",
        "    print(\"NLTK data downloaded successfully!\\n\")\n",
        "except:\n",
        "    print(\"NLTK data download failed. Using fallback options.\\n\")\n",
        "    NLTK_AVAILABLE = False\n",
        "\n",
        "class AdvancedTextProcessor:\n",
        "    def __init__(self, language='english'):\n",
        "        self.language = language\n",
        "        self.porter = PorterStemmer()\n",
        "        self.snowball = SnowballStemmer(language)\n",
        "        self.lancaster = LancasterStemmer()\n",
        "        self.lemmatizer = WordNetLemmatizer() if NLTK_AVAILABLE else None\n",
        "\n",
        "        try:\n",
        "            self.stop_words = set(stopwords.words(language)) if NLTK_AVAILABLE else STOP_WORDS\n",
        "        except:\n",
        "            self.stop_words = STOP_WORDS\n",
        "\n",
        "    def get_wordnet_pos(self, word):\n",
        "        if NLTK_AVAILABLE:\n",
        "            tag = pos_tag([word])[0][1][0].upper()\n",
        "            return {'J': 'a', 'N': 'n', 'V': 'v', 'R': 'r'}.get(tag, 'n')\n",
        "        return 'n'\n",
        "\n",
        "    def tokenize_text(self, text: str, remove_punc=True, remove_stop=True, min_len=2) -> List[str]:\n",
        "        tokens = word_tokenize(text.lower()) if NLTK_AVAILABLE else simple_tokenize(text)\n",
        "\n",
        "        if remove_punc:\n",
        "            tokens = [t for t in tokens if t not in string.punctuation]\n",
        "        if remove_stop:\n",
        "            tokens = [t for t in tokens if t not in self.stop_words]\n",
        "\n",
        "        return [t for t in tokens if len(t) >= min_len and not t.isdigit()]\n",
        "\n",
        "    def stem_and_lemmatize_comparison(self, text: str) -> Dict[str, List[str]]:\n",
        "        tokens = self.tokenize_text(text)\n",
        "\n",
        "        porter = [self.porter.stem(w) for w in tokens]\n",
        "        snowball = [self.snowball.stem(w) for w in tokens]\n",
        "        lancaster = [self.lancaster.stem(w) for w in tokens]\n",
        "\n",
        "        lemmas = []\n",
        "        for token in tokens:\n",
        "            if self.lemmatizer:\n",
        "                try:\n",
        "                    pos = self.get_wordnet_pos(token)\n",
        "                    lemmas.append(self.lemmatizer.lemmatize(token, pos=pos))\n",
        "                except:\n",
        "                    lemmas.append(token)\n",
        "            else:\n",
        "                lemmas.append(token)\n",
        "\n",
        "        return {\n",
        "            'original_tokens': tokens,\n",
        "            'porter_stems': porter,\n",
        "            'snowball_stems': snowball,\n",
        "            'lancaster_stems': lancaster,\n",
        "            'lemmas': lemmas\n",
        "        }\n",
        "\n",
        "    def detailed_analysis(self, text: str) -> Dict:\n",
        "        result = self.stem_and_lemmatize_comparison(text)\n",
        "        df = pd.DataFrame({\n",
        "            'Original': result['original_tokens'],\n",
        "            'Porter': result['porter_stems'],\n",
        "            'Snowball': result['snowball_stems'],\n",
        "            'Lancaster': result['lancaster_stems'],\n",
        "            'Lemma': result['lemmas']\n",
        "        })\n",
        "\n",
        "        unique_tokens = len(set(result['original_tokens']))\n",
        "\n",
        "        stats = {\n",
        "            'total_tokens': len(result['original_tokens']),\n",
        "            'unique_tokens': unique_tokens,\n",
        "            'porter_unique': len(set(result['porter_stems'])),\n",
        "            'snowball_unique': len(set(result['snowball_stems'])),\n",
        "            'lancaster_unique': len(set(result['lancaster_stems'])),\n",
        "            'lemma_unique': len(set(result['lemmas'])),\n",
        "        }\n",
        "\n",
        "        for key in ['porter', 'snowball', 'lancaster', 'lemma']:\n",
        "            stats[f'{key}_reduction'] = (\n",
        "                (unique_tokens - stats[f'{key}_unique']) / unique_tokens * 100\n",
        "                if unique_tokens > 0 else 0\n",
        "            )\n",
        "\n",
        "        return {'dataframe': df, 'statistics': stats, 'raw_results': result}\n",
        "\n",
        "    def find_differences(self, text: str) -> pd.DataFrame:\n",
        "        res = self.stem_and_lemmatize_comparison(text)\n",
        "        diffs = []\n",
        "        for i, word in enumerate(res['original_tokens']):\n",
        "            forms = [res['porter_stems'][i], res['snowball_stems'][i],\n",
        "                     res['lancaster_stems'][i], res['lemmas'][i]]\n",
        "            if len(set(forms)) > 1:\n",
        "                diffs.append({\n",
        "                    'Original': word,\n",
        "                    'Porter': forms[0],\n",
        "                    'Snowball': forms[1],\n",
        "                    'Lancaster': forms[2],\n",
        "                    'Lemma': forms[3],\n",
        "                    'Unique_Forms': len(set(forms))\n",
        "                })\n",
        "        return pd.DataFrame(diffs)\n",
        "\n",
        "    def show_comparison_table(self, text: str):\n",
        "        res = self.stem_and_lemmatize_comparison(text)\n",
        "        print(f\"\\n{'Original':<15}{'Porter':<15}{'Snowball':<15}{'Lancaster':<15}{'Lemma':<15}\")\n",
        "        print(\"-\" * 75)\n",
        "        for i in range(len(res['original_tokens'])):\n",
        "            print(f\"{res['original_tokens'][i]:<15}{res['porter_stems'][i]:<15}\"\n",
        "                  f\"{res['snowball_stems'][i]:<15}{res['lancaster_stems'][i]:<15}\"\n",
        "                  f\"{res['lemmas'][i]:<15}\")\n",
        "\n",
        "def demonstrate_stemmer_lemmatizer_characteristics():\n",
        "    processor = AdvancedTextProcessor()\n",
        "    test_words = [\n",
        "        'scoring', 'dribbling', 'passes', 'teams', 'players', 'better', 'good',\n",
        "        'strikers', 'defending', 'played', 'running', 'feet', 'goals', 'won', 'losses'\n",
        "    ]\n",
        "    print(\"=== STEMMER vs LEMMATIZER CHARACTERISTICS ===\\n\")\n",
        "    print(f\"{'Word':<15}{'Porter':<15}{'Snowball':<15}{'Lancaster':<15}{'Lemma':<15}\")\n",
        "    print(\"-\" * 75)\n",
        "    for word in test_words:\n",
        "        porter = processor.porter.stem(word)\n",
        "        snowball = processor.snowball.stem(word)\n",
        "        lancaster = processor.lancaster.stem(word)\n",
        "        lemma = processor.lemmatizer.lemmatize(word, processor.get_wordnet_pos(word)) \\\n",
        "            if processor.lemmatizer else word\n",
        "        print(f\"{word:<15}{porter:<15}{snowball:<15}{lancaster:<15}{lemma:<15}\")\n",
        "\n",
        "def main():\n",
        "    processor = AdvancedTextProcessor()\n",
        "    demonstrate_stemmer_lemmatizer_characteristics()\n",
        "\n",
        "    football_text = \"\"\"\n",
        "    Football is one of the most followed sports globally. Clubs like Real Madrid,\n",
        "    Barcelona, and Liverpool have millions of fans and rich histories. Players train\n",
        "    for hours to master passing, shooting, and dribbling. The Champions League is\n",
        "    considered the most prestigious club competition in Europe. Rivalries like El\n",
        "    Clasico between Madrid and Barca create intense excitement. Young talents like\n",
        "    Jude Bellingham and Ansu Fati are rising stars in the football world.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"FOOTBALL TEXT ANALYSIS\".center(80))\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    analysis = processor.detailed_analysis(football_text)\n",
        "    stats = analysis['statistics']\n",
        "\n",
        "    print(\"\\nSTATISTICS:\")\n",
        "    for k, v in stats.items():\n",
        "        if \"reduction\" in k:\n",
        "            print(f\"{k.replace('_', ' ').title()}: {v:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{k.replace('_', ' ').title()}: {v}\")\n",
        "\n",
        "    print(\"\\nCOMPARISON TABLE:\")\n",
        "    processor.show_comparison_table(football_text)\n",
        "\n",
        "    diff = processor.find_differences(football_text)\n",
        "    if not diff.empty:\n",
        "        print(\"\\nWORDS WITH DIFFERENT FORMS:\")\n",
        "        print(diff.to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\nNo significant differences found.\")\n",
        "\n",
        "    print(\"\\nMOST FREQUENT FORMS:\")\n",
        "    for method in ['porter_stems', 'snowball_stems', 'lancaster_stems', 'lemmas']:\n",
        "        freq = Counter(analysis['raw_results'][method]).most_common(5)\n",
        "        print(f\"{method.replace('_', ' ').title()}: {freq}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RECOMMENDATION: Use lemmatization for better semantic accuracy!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\" * 80)\n",
        "    print(\"Developed by Harsh Rawte | Roll No: 22101A0047\".center(80))\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        ""
      ],
      "metadata": {
        "id": "Kuwk770_uK3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from typing import List, Dict, Tuple, Set\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "class IndicTokenizer:\n",
        "    \"\"\"Custom tokenizer for Hindi and Marathi using Indic-specific rules\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define Devanagari Unicode ranges\n",
        "        self.devanagari_range = r'\\u0900-\\u097F'\n",
        "        self.punctuation = r'[।॥॰\\.\\,\\;\\:\\!\\?\\\"\\'\\(\\)\\[\\]\\{\\}\\-\\—\\–\\…\\'\\'\\\"\\\"]'\n",
        "        self.numbers = r'[०-९0-9]+'\n",
        "        self.english_words = r'[a-zA-Z]+'\n",
        "\n",
        "        # Common Hindi/Marathi conjuncts and special characters\n",
        "        self.conjuncts = ['क्ष', 'त्र', 'ज्ञ', 'श्र', 'द्व', 'द्य', 'त्त', 'न्न', 'म्म', 'ल्ल']\n",
        "\n",
        "        # Compound word separators\n",
        "        self.compound_separators = ['-', '–', '—', '/', '+']\n",
        "\n",
        "    def tokenize(self, text: str, language: str = 'hi') -> List[str]:\n",
        "        \"\"\"\n",
        "        Tokenize text using Indic-specific rules\n",
        "        Args:\n",
        "            text: Input text\n",
        "            language: 'hi' for Hindi, 'mr' for Marathi\n",
        "        Returns:\n",
        "            List of tokens\n",
        "        \"\"\"\n",
        "        if not text:\n",
        "            return []\n",
        "\n",
        "        # Normalize text\n",
        "        text = unicodedata.normalize('NFC', text)\n",
        "\n",
        "        # Handle compound words\n",
        "        text = self._handle_compound_words(text)\n",
        "\n",
        "        # Split on whitespace and punctuation\n",
        "        tokens = []\n",
        "        current_token = \"\"\n",
        "\n",
        "        for char in text:\n",
        "            if char.isspace():\n",
        "                if current_token:\n",
        "                    tokens.append(current_token)\n",
        "                    current_token = \"\"\n",
        "            elif re.match(self.punctuation, char):\n",
        "                if current_token:\n",
        "                    tokens.append(current_token)\n",
        "                    current_token = \"\"\n",
        "                tokens.append(char)\n",
        "            else:\n",
        "                current_token += char\n",
        "\n",
        "        if current_token:\n",
        "            tokens.append(current_token)\n",
        "\n",
        "        # Filter out empty tokens and single characters (except meaningful ones)\n",
        "        meaningful_single_chars = {\n",
        "            '।', '॥', 'व', 'न', 'म', 'क', 'र', 'स', 'त', 'द', 'प', 'ब', 'य',\n",
        "            'ल', 'ह', 'ज', 'ग', 'च', 'श', 'ष', 'थ', 'ध', 'भ', 'फ', 'ख', 'घ',\n",
        "            'छ', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'ि', '्'\n",
        "        }\n",
        "\n",
        "        filtered_tokens = []\n",
        "        for token in tokens:\n",
        "            if len(token) > 1 or token in meaningful_single_chars:\n",
        "                filtered_tokens.append(token)\n",
        "\n",
        "        return filtered_tokens\n",
        "\n",
        "    def _handle_compound_words(self, text: str) -> str:\n",
        "        \"\"\"Handle compound words by preserving meaningful separators\"\"\"\n",
        "        for sep in self.compound_separators:\n",
        "            # Don't split if it's likely a compound word\n",
        "            text = re.sub(f'([{self.devanagari_range}]){re.escape(sep)}([{self.devanagari_range}])',\n",
        "                         r'\\1\\2', text)\n",
        "        return text\n",
        "\n",
        "class ManualStemmer:\n",
        "    \"\"\"Manual rule-based stemmer for Hindi and Marathi\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.hindi_rules = self._create_hindi_rules()\n",
        "        self.marathi_rules = self._create_marathi_rules()\n",
        "\n",
        "    def _create_hindi_rules(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Create manual stemming rules for Hindi\"\"\"\n",
        "        rules = [\n",
        "            # Plural suffixes\n",
        "            ('ियाँ$', 'ी'),  # टीमियाँ -> टीमी\n",
        "            ('ियों$', 'ी'),  # टीमियों -> टीमी\n",
        "            ('ों$', ''),    # खिलाड़ियों -> खिलाड़ी\n",
        "            ('ें$', ''),    # मैचें -> मैच\n",
        "            ('ियां$', 'ी'), # टीमियां -> टीमी\n",
        "            ('ाओं$', 'ा'),  # क्लबों -> क्लब\n",
        "            ('ाएँ$', 'ा'),  # गोलाएँ -> गोला\n",
        "\n",
        "            # Verb forms\n",
        "            ('ता$', ''),   # खेलता -> खेल\n",
        "            ('ते$', ''),   # खेलते -> खेल\n",
        "            ('ती$', ''),   # खेलती -> खेल\n",
        "            ('ना$', ''),   # खेलना -> खेल\n",
        "            ('नी$', ''),   # खेलनी -> खेल\n",
        "            ('ने$', ''),   # खेलने -> खेल\n",
        "            ('या$', ''),    # किया -> कि\n",
        "            ('ये$', ''),    # किये -> कि\n",
        "            ('याँ$', ''),   # कियाँ -> कि\n",
        "            ('एगा$', ''),   # खेलेगा -> खेल\n",
        "            ('एगी$', ''),   # खेलेगी -> खेल\n",
        "            ('एंगे$', ''),  # खेलेंगे -> खेल\n",
        "            ('ेंगे$', ''),  # खेलेंगे -> खेल\n",
        "            ('ेंगी$', ''),  # खेलेंगी -> खेल\n",
        "            ('ोगे$', ''),   # खेलोगे -> खेल\n",
        "            ('ोगी$', ''),   # खेलोगी -> खेल\n",
        "\n",
        "            # Adjective forms\n",
        "            ('वान$', ''),  # प्रतिभावान -> प्रतिभा\n",
        "            ('मान$', ''),  # कुशलमान -> कुशल\n",
        "            ('दार$', ''),  # जिम्मेदार -> जिम्मे\n",
        "            ('कार$', ''),  # प्रशिक्षक -> प्रशिक्ष\n",
        "            ('हार$', ''),  # गोलहार -> गोल\n",
        "            ('वाला$', ''),  # खेलनेवाला -> खेलने\n",
        "            ('वाले$', ''),  # खेलनेवाले -> खेलने\n",
        "            ('वाली$', ''),  # खेलनेवाली -> खेलने\n",
        "\n",
        "            # Case markers\n",
        "            ('से$', ''),   # मैदान से -> मैदान\n",
        "            ('में$', ''),   # मैदान में -> मैदान\n",
        "            ('पर$', ''),   # मैदान पर -> मैदान\n",
        "            ('का$', ''),   # टीम का -> टीम\n",
        "            ('के$', ''),   # टीम के -> टीम\n",
        "            ('की$', ''),   # टीम की -> टीम\n",
        "            ('को$', ''),   # टीम को -> टीम\n",
        "            ('पे$', ''),   # मैदान पे -> मैदान\n",
        "            ('तक$', ''),  # अंत तक -> अंत\n",
        "\n",
        "            # Diminutive and augmentative\n",
        "            ('जी$', ''),   # कोच जी -> कोच\n",
        "            ('साहब$', ''),  # मैनेजरसाहब -> मैनेजर\n",
        "            ('बाबू$', ''),  # रेफरीबाबू -> रेफरी\n",
        "            ('जान$', ''),  # कप्तानजान -> कप्तान\n",
        "\n",
        "            # Abstract noun suffixes\n",
        "            ('ता$', ''),   # गतिशीलता -> गतिशील\n",
        "            ('त्व$', ''),   # खिलाड़ित्व -> खिलाड़ी\n",
        "            ('पन$', ''),   # कप्तानपन -> कप्तान\n",
        "            ('आहट$', ''),  # जीताहट -> जीता\n",
        "            ('आवट$', ''),  # सजावट -> सजा\n",
        "            ('इयत$', ''),  # प्रतियोगिता -> प्रतियोगि\n",
        "\n",
        "            # Tense markers\n",
        "            ('था$', ''),   # खेला था -> खेला\n",
        "            ('थे$', ''),   # खेले थे -> खेले\n",
        "            ('थी$', ''),   # खेली थी -> खेली\n",
        "            ('हूँ$', ''),   # खेलता हूँ -> खेलता\n",
        "            ('हैं$', ''),   # खेलते हैं -> खेलते\n",
        "            ('है$', ''),   # खेलता है -> खेलता\n",
        "        ]\n",
        "        return rules\n",
        "\n",
        "    def _create_marathi_rules(self) -> List[Tuple[str, str]]:\n",
        "        \"\"\"Create manual stemming rules for Marathi\"\"\"\n",
        "        rules = [\n",
        "            # Plural suffixes\n",
        "            ('ेणे$', ''),  # सामनेणे -> सामना\n",
        "            ('ांना$', ''),  # खेळाडूंना -> खेळाडू\n",
        "            ('ांचा$', ''),  # क्लबांचा -> क्लब\n",
        "            ('ांची$', ''),  # क्लबांची -> क्लब\n",
        "            ('ांच्या$', ''),  # क्लबांच्या -> क्लब\n",
        "            ('ांमध्ये$', ''),  # क्लबांमध्ये -> क्लब\n",
        "            ('ांसाठी$', ''),  # क्लबांसाठी -> क्लब\n",
        "\n",
        "            # Verb forms\n",
        "            ('तो$', ''),   # खेळतो -> खेळ\n",
        "            ('ते$', ''),   # खेळते -> खेळ\n",
        "            ('ता$', ''),   # खेळता -> खेळ\n",
        "            ('तात$', ''),  # खेळतात -> खेळ\n",
        "            ('ला$', ''),   # जिंकला -> जिंक\n",
        "            ('ली$', ''),   # जिंकली -> जिंक\n",
        "            ('ले$', ''),   # जिंकले -> जिंक\n",
        "            ('लो$', ''),   # जिंकलो -> जिंक\n",
        "            ('ील$', ''),   # खेळील -> खेळ\n",
        "            ('ाल$', ''),   # खेळाल -> खेळ\n",
        "            ('ायचे$', ''),  # खेळायचे -> खेळ\n",
        "            ('ायचा$', ''),  # खेळायचा -> खेळ\n",
        "            ('ायची$', ''),  # खेळायची -> खेळ\n",
        "            ('ायच्या$', ''),  # खेळायच्या -> खेळ\n",
        "\n",
        "            # Case markers\n",
        "            ('ला$', ''),   # मैदानला -> मैदान\n",
        "            ('चा$', ''),   # टीमचा -> टीम\n",
        "            ('ची$', ''),   # टीमची -> टीम\n",
        "            ('च्या$', ''),  # टीमच्या -> टीम\n",
        "            ('मध्ये$', ''),  # मैदानमध्ये -> मैदान\n",
        "            ('वर$', ''),   # मैदानवर -> मैदान\n",
        "            ('खाली$', ''),  # मैदानखाली -> मैदान\n",
        "            ('जवळ$', ''),  # मैदानजवळ -> मैदान\n",
        "            ('पुढे$', ''),  # मैदानपुढे -> मैदान\n",
        "            ('मागे$', ''),  # मैदानमागे -> मैदान\n",
        "            ('शी$', ''),   # कोचशी -> कोच\n",
        "            ('कडे$', ''),  # कोचकडे -> कोच\n",
        "            ('साठी$', ''),  # कोचसाठी -> कोच\n",
        "\n",
        "            # Adjective forms\n",
        "            ('वान$', ''),  # प्रतिभावान -> प्रतिभा\n",
        "            ('मान$', ''),  # कुशलमान -> कुशल\n",
        "            ('दार$', ''),  # जबाबदार -> जबाब\n",
        "            ('कार$', ''),  # प्रशिक्षक -> प्रशिक्ष\n",
        "            ('णारा$', ''),  # खेळणारा -> खेळ\n",
        "            ('णारे$', ''),  # खेळणारे -> खेळ\n",
        "            ('णारी$', ''),  # खेळणारी -> खेळ\n",
        "\n",
        "            # Abstract noun suffixes\n",
        "            ('ता$', ''),   # गतिशीलता -> गतिशील\n",
        "            ('त्व$', ''),   # खेळाडूत्व -> खेळाडू\n",
        "            ('पणा$', ''),  # कप्तानपणा -> कप्तान\n",
        "            ('ाई$', ''),  # ज्येष्ठाई -> ज्येष्ठ\n",
        "            ('ीक$', ''),  # स्पर्धात्मक -> स्पर्धा\n",
        "\n",
        "            # Honorific suffixes\n",
        "            ('जी$', ''),   # कोचजी -> कोच\n",
        "            ('साहेब$', ''),  # मैनेजरसाहेब -> मैनेजर\n",
        "            ('राव$', ''),  # रेफरीराव -> रेफरी\n",
        "            ('ाजी$', ''),  # कप्तानाजी -> कप्तान\n",
        "            ('काका$', ''),  # रेफरीकाका -> रेफरी\n",
        "\n",
        "            # Tense markers\n",
        "            ('होतो$', ''),  # खेळत होतो -> खेळत\n",
        "            ('होते$', ''),  # खेळत होते -> खेळत\n",
        "            ('होती$', ''),  # खेळत होती -> खेळत\n",
        "            ('आहे$', ''),  # खेळत आहे -> खेळत\n",
        "            ('आहेत$', ''),  # खेळत आहेत -> खेळत\n",
        "        ]\n",
        "        return rules\n",
        "\n",
        "    def stem(self, word: str, language: str) -> str:\n",
        "        \"\"\"\n",
        "        Apply manual stemming rules\n",
        "        Args:\n",
        "            word: Input word\n",
        "            language: 'hi' for Hindi, 'mr' for Marathi\n",
        "        Returns:\n",
        "            Stemmed word\n",
        "        \"\"\"\n",
        "        if not word:\n",
        "            return word\n",
        "\n",
        "        rules = self.hindi_rules if language == 'hi' else self.marathi_rules\n",
        "\n",
        "        # Apply rules in order\n",
        "        for pattern, replacement in rules:\n",
        "            if re.search(pattern, word):\n",
        "                stemmed = re.sub(pattern, replacement, word)\n",
        "                if stemmed and stemmed != word:\n",
        "                    return stemmed\n",
        "\n",
        "        return word\n",
        "\n",
        "class PretrainedStemmer:\n",
        "    \"\"\"Wrapper for pretrained stemming models\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Simulated pretrained models (in practice, these would be loaded from files)\n",
        "        self.hindi_model = self._load_hindi_model()\n",
        "        self.marathi_model = self._load_marathi_model()\n",
        "\n",
        "    def _load_hindi_model(self) -> Dict[str, str]:\n",
        "        \"\"\"Simulate loading a pretrained Hindi stemmer\"\"\"\n",
        "        # This would typically load from a file or model\n",
        "        return {\n",
        "            'फुटबॉल': 'फुटबॉल',\n",
        "            'खिलाड़ी': 'खिलाड़',\n",
        "            'खिलाड़ियों': 'खिलाड़',\n",
        "            'टीम': 'टीम',\n",
        "            'टीमों': 'टीम',\n",
        "            'मैच': 'मैच',\n",
        "            'मैचों': 'मैच',\n",
        "            'गोल': 'गोल',\n",
        "            'गोलों': 'गोल',\n",
        "            'कप्तान': 'कप्तान',\n",
        "            'कप्तानों': 'कप्तान',\n",
        "            'प्रशिक्षक': 'प्रशिक्षक',\n",
        "            'प्रशिक्षकों': 'प्रशिक्षक',\n",
        "            'बार्सिलोना': 'बार्सिलोना',\n",
        "            'रियलमैड्रिड': 'रियलमैड्रिड',\n",
        "            'लिवरपूल': 'लिवरपूल',\n",
        "            'प्रीमियरलीग': 'प्रीमियरलीग',\n",
        "            'लालिगा': 'लालिगा',\n",
        "            'चैंपियंसलीग': 'चैंपियंसलीग',\n",
        "            'जीत': 'जीत',\n",
        "            'जीतें': 'जीत',\n",
        "            'हार': 'हार',\n",
        "            'हारें': 'हार',\n",
        "            'खेल': 'खेल',\n",
        "            'खेलना': 'खेल',\n",
        "            'खेलते': 'खेल',\n",
        "            'मैदान': 'मैदान',\n",
        "            'प्रशंसक': 'प्रशंसक',\n",
        "            'प्रशंसकों': 'प्रशंसक',\n",
        "            'स्टेडियम': 'स्टेडियम',\n",
        "            'स्पर्धा': 'स्पर्धा',\n",
        "            'प्रतियोगिता': 'प्रतियोगिता',\n",
        "            'क्लब': 'क्लब',\n",
        "            'लीडरबोर्ड': 'लीडरबोर्ड',\n",
        "            'पेनाल्टी': 'पेनाल्टी',\n",
        "            'फाउल': 'फाउल',\n",
        "            'रेफरी': 'रेफरी',\n",
        "            'अंपायर': 'अंपायर',\n",
        "            'ट्रॉफी': 'ट्रॉफी',\n",
        "            'सीजन': 'सीजन'\n",
        "        }\n",
        "\n",
        "    def _load_marathi_model(self) -> Dict[str, str]:\n",
        "        \"\"\"Simulate loading a pretrained Marathi stemmer\"\"\"\n",
        "        return {\n",
        "            'फुटबॉल': 'फुटबॉल',\n",
        "            'खेळाडू': 'खेळाडू',\n",
        "            'खेळाडूंना': 'खेळाडू',\n",
        "            'संघ': 'संघ',\n",
        "            'संघांना': 'संघ',\n",
        "            'सामना': 'सामना',\n",
        "            'सामने': 'सामना',\n",
        "            'गोल': 'गोल',\n",
        "            'गोलं': 'गोल',\n",
        "            'कर्णधार': 'कर्णधार',\n",
        "            'कर्णधारांना': 'कर्णधार',\n",
        "            'प्रशिक्षक': 'प्रशिक्षक',\n",
        "            'प्रशिक्षकांना': 'प्रशिक्षक',\n",
        "            'बार्सिलोना': 'बार्सिलोना',\n",
        "            'रियलमैड्रिड': 'रियलमैड्रिड',\n",
        "            'लिवरपूल': 'लिवरपूल',\n",
        "            'प्रीमियरलीग': 'प्रीमियरलीग',\n",
        "            'ला लीगा': 'ला लीगा',\n",
        "            'चॅम्पियन्सलीग': 'चॅम्पियन्सलीग',\n",
        "            'विजय': 'विजय',\n",
        "            'विजयांना': 'विजय',\n",
        "            'पराभव': 'पराभव',\n",
        "            'पराभवांना': 'पराभव',\n",
        "            'खेळ': 'खेळ',\n",
        "            'खेळायचे': 'खेळ',\n",
        "            'खेळतात': 'खेळ',\n",
        "            'मैदान': 'मैदान',\n",
        "            'प्रेक्षक': 'प्रेक्षक',\n",
        "            'प्रेक्षकांना': 'प्रेक्षक',\n",
        "            'स्टेडियम': 'स्टेडियम',\n",
        "            'स्पर्धा': 'स्पर्धा',\n",
        "            'स्पर्धांना': 'स्पर्धा',\n",
        "            'क्लब': 'क्लब',\n",
        "            'लीडरबोर्ड': 'लीडरबोर्ड',\n",
        "            'पेनाल्टी': 'पेनाल्टी',\n",
        "            'फाउल': 'फाउल',\n",
        "            'रेफरी': 'रेफरी',\n",
        "            'अंपायर': 'अंपायर',\n",
        "            'ट्रॉफी': 'ट्रॉफी',\n",
        "            'हंगाम': 'हंगाम'\n",
        "        }\n",
        "\n",
        "    def stem(self, word: str, language: str) -> str:\n",
        "        \"\"\"\n",
        "        Apply pretrained stemming model\n",
        "        Args:\n",
        "            word: Input word\n",
        "            language: 'hi' for Hindi, 'mr' for Marathi\n",
        "        Returns:\n",
        "            Stemmed word\n",
        "        \"\"\"\n",
        "        if not word:\n",
        "            return word\n",
        "\n",
        "        model = self.hindi_model if language == 'hi' else self.marathi_model\n",
        "        return model.get(word, word)\n",
        "\n",
        "class MultilingualProcessor:\n",
        "    \"\"\"Main processor combining tokenization and stemming\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.tokenizer = IndicTokenizer()\n",
        "        self.manual_stemmer = ManualStemmer()\n",
        "        self.pretrained_stemmer = PretrainedStemmer()\n",
        "\n",
        "    def process_text(self, text: str, language: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Process text through tokenization and both stemming approaches\n",
        "        Args:\n",
        "            text: Input text\n",
        "            language: 'hi' for Hindi, 'mr' for Marathi\n",
        "        Returns:\n",
        "            Dictionary with results\n",
        "        \"\"\"\n",
        "        # Tokenization\n",
        "        start_time = time.time()\n",
        "        tokens = self.tokenizer.tokenize(text, language)\n",
        "        tokenization_time = time.time() - start_time\n",
        "\n",
        "        # Manual stemming\n",
        "        start_time = time.time()\n",
        "        manual_stems = [self.manual_stemmer.stem(token, language) for token in tokens]\n",
        "        manual_stemming_time = time.time() - start_time\n",
        "\n",
        "        # Pretrained stemming\n",
        "        start_time = time.time()\n",
        "        pretrained_stems = [self.pretrained_stemmer.stem(token, language) for token in tokens]\n",
        "        pretrained_stemming_time = time.time() - start_time\n",
        "\n",
        "        return {\n",
        "            'original_text': text,\n",
        "            'language': language,\n",
        "            'tokens': tokens,\n",
        "            'token_count': len(tokens),\n",
        "            'manual_stems': manual_stems,\n",
        "            'pretrained_stems': pretrained_stems,\n",
        "            'tokenization_time': tokenization_time,\n",
        "            'manual_stemming_time': manual_stemming_time,\n",
        "            'pretrained_stemming_time': pretrained_stemming_time\n",
        "        }\n",
        "\n",
        "    def compare_stemmers(self, test_words: List[str], language: str) -> Dict:\n",
        "        \"\"\"\n",
        "        Compare manual and pretrained stemming approaches\n",
        "        Args:\n",
        "            test_words: List of words to test\n",
        "            language: 'hi' for Hindi, 'mr' for Marathi\n",
        "        Returns:\n",
        "            Comparison results\n",
        "        \"\"\"\n",
        "        results = {\n",
        "            'word': [],\n",
        "            'manual_stem': [],\n",
        "            'pretrained_stem': [],\n",
        "            'agreement': [],\n",
        "            'manual_reduction': [],\n",
        "            'pretrained_reduction': []\n",
        "        }\n",
        "\n",
        "        for word in test_words:\n",
        "            manual_stem = self.manual_stemmer.stem(word, language)\n",
        "            pretrained_stem = self.pretrained_stemmer.stem(word, language)\n",
        "\n",
        "            results['word'].append(word)\n",
        "            results['manual_stem'].append(manual_stem)\n",
        "            results['pretrained_stem'].append(pretrained_stem)\n",
        "            results['agreement'].append(manual_stem == pretrained_stem)\n",
        "            results['manual_reduction'].append(len(word) - len(manual_stem))\n",
        "            results['pretrained_reduction'].append(len(word) - len(pretrained_stem))\n",
        "\n",
        "        # Calculate statistics\n",
        "        agreement_rate = sum(results['agreement']) / len(results['agreement'])\n",
        "        avg_manual_reduction = sum(results['manual_reduction']) / len(results['manual_reduction'])\n",
        "        avg_pretrained_reduction = sum(results['pretrained_reduction']) / len(results['pretrained_reduction'])\n",
        "\n",
        "        return {\n",
        "            'detailed_results': results,\n",
        "            'agreement_rate': agreement_rate,\n",
        "            'avg_manual_reduction': avg_manual_reduction,\n",
        "            'avg_pretrained_reduction': avg_pretrained_reduction\n",
        "        }\n",
        "\n",
        "# Example usage and testing\n",
        "def main():\n",
        "    processor = MultilingualProcessor()\n",
        "\n",
        "    # Test Hindi text - Football match description\n",
        "    hindi_text = \"\"\"बार्सिलोना और रियल मैड्रिड के बीच एल क्लासिको मैच रविवार को होगा।\n",
        "    दोनों टीमें ला लीगा के शीर्ष स्थान के लिए प्रतिस्पर्धा कर रही हैं।\n",
        "    मैच में मेसी और रोनाल्डो के प्रदर्शन पर सभी की नजर होगी।\n",
        "    कैंप नोउ स्टेडियम में होने वाले इस मैच में 90000 से अधिक प्रशंसक उपस्थित रहेंगे।\"\"\"\n",
        "\n",
        "    # Test Marathi text - Football match description\n",
        "    marathi_text = \"\"\"बार्सिलोना आणि रियल मैड्रिड यांच्यातील एल क्लासिको सामना रविवारी होणार आहे.\n",
        "    दोन्ही संघ ला लीगा मध्ये अव्वल स्थानासाठी स्पर्धा करत आहेत.\n",
        "    सामन्यात मेस्सी आणि रोनाल्डो यांच्या कामगिरीवर सर्वांचे लक्ष असेल.\n",
        "    कॅम्प नोउ स्टेडियम मध्ये होणाऱ्या या सामन्यात 90000 हून अधिक प्रेक्षक उपस्थित असतील.\"\"\"\n",
        "    print(\"Harsh Rawte 22101A0047\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"=== HINDI TEXT PROCESSING (Football Match) ===\")\n",
        "    hindi_results = processor.process_text(hindi_text, 'hi')\n",
        "    print(f\"Original text length: {len(hindi_results['original_text'])} characters\")\n",
        "    print(f\"Token count: {hindi_results['token_count']}\")\n",
        "    print(f\"First 10 tokens: {hindi_results['tokens'][:10]}\")\n",
        "    print(f\"First 10 manual stems: {hindi_results['manual_stems'][:10]}\")\n",
        "    print(f\"First 10 pretrained stems: {hindi_results['pretrained_stems'][:10]}\")\n",
        "    print(f\"Tokenization time: {hindi_results['tokenization_time']:.4f}s\")\n",
        "    print(f\"Manual stemming time: {hindi_results['manual_stemming_time']:.4f}s\")\n",
        "    print(f\"Pretrained stemming time: {hindi_results['pretrained_stemming_time']:.4f}s\")\n",
        "\n",
        "    print(\"\\n=== MARATHI TEXT PROCESSING (Football Match) ===\")\n",
        "    marathi_results = processor.process_text(marathi_text, 'mr')\n",
        "    print(f\"Original text length: {len(marathi_results['original_text'])} characters\")\n",
        "    print(f\"Token count: {marathi_results['token_count']}\")\n",
        "    print(f\"First 10 tokens: {marathi_results['tokens'][:10]}\")\n",
        "    print(f\"First 10 manual stems: {marathi_results['manual_stems'][:10]}\")\n",
        "    print(f\"First 10 pretrained stems: {marathi_results['pretrained_stems'][:10]}\")\n",
        "    print(f\"Tokenization time: {marathi_results['tokenization_time']:.4f}s\")\n",
        "    print(f\"Manual stemming time: {marathi_results['manual_stemming_time']:.4f}s\")\n",
        "    print(f\"Pretrained stemming time: {marathi_results['pretrained_stemming_time']:.4f}s\")\n",
        "\n",
        "    # Analysis of unique tokens vs stems\n",
        "    print(\"\\n=== HINDI VOCABULARY ANALYSIS ===\")\n",
        "    hindi_unique_tokens = set(hindi_results['tokens'])\n",
        "    hindi_unique_manual_stems = set(hindi_results['manual_stems'])\n",
        "    hindi_unique_pretrained_stems = set(hindi_results['pretrained_stems'])\n",
        "\n",
        "    print(f\"Unique tokens: {len(hindi_unique_tokens)}\")\n",
        "    print(f\"Unique manual stems: {len(hindi_unique_manual_stems)}\")\n",
        "    print(f\"Unique pretrained stems: {len(hindi_unique_pretrained_stems)}\")\n",
        "    print(f\"Vocabulary reduction (manual): {len(hindi_unique_tokens) - len(hindi_unique_manual_stems)}\")\n",
        "    print(f\"Vocabulary reduction (pretrained): {len(hindi_unique_tokens) - len(hindi_unique_pretrained_stems)}\")\n",
        "\n",
        "    print(\"\\n=== MARATHI VOCABULARY ANALYSIS ===\")\n",
        "    marathi_unique_tokens = set(marathi_results['tokens'])\n",
        "    marathi_unique_manual_stems = set(marathi_results['manual_stems'])\n",
        "    marathi_unique_pretrained_stems = set(marathi_results['pretrained_stems'])\n",
        "\n",
        "    print(f\"Unique tokens: {len(marathi_unique_tokens)}\")\n",
        "    print(f\"Unique manual stems: {len(marathi_unique_manual_stems)}\")\n",
        "    print(f\"Unique pretrained stems: {len(marathi_unique_pretrained_stems)}\")\n",
        "    print(f\"Vocabulary reduction (manual): {len(marathi_unique_tokens) - len(marathi_unique_manual_stems)}\")\n",
        "    print(f\"Vocabulary reduction (pretrained): {len(marathi_unique_tokens) - len(marathi_unique_pretrained_stems)}\")\n",
        "\n",
        "    # Sample comparison of stems\n",
        "    print(\"\\n=== SAMPLE STEM COMPARISON (Hindi) ===\")\n",
        "    print(f\"{'Token':<20} {'Manual':<20} {'Pretrained':<20} {'Reduction':<10}\")\n",
        "    print(\"-\" * 75)\n",
        "    for i, (token, manual, pretrained) in enumerate(zip(\n",
        "        hindi_results['tokens'][:15],\n",
        "        hindi_results['manual_stems'][:15],\n",
        "        hindi_results['pretrained_stems'][:15]\n",
        "    )):\n",
        "        reduction = len(token) - len(manual)\n",
        "        print(f\"{token:<20} {manual:<20} {pretrained:<20} {reduction:<10}\")\n",
        "\n",
        "    print(\"\\n=== SAMPLE STEM COMPARISON (Marathi) ===\")\n",
        "    print(f\"{'Token':<20} {'Manual':<20} {'Pretrained':<20} {'Reduction':<10}\")\n",
        "    print(\"-\" * 75)\n",
        "    for i, (token, manual, pretrained) in enumerate(zip(\n",
        "        marathi_results['tokens'][:15],\n",
        "        marathi_results['manual_stems'][:15],\n",
        "        marathi_results['pretrained_stems'][:15]\n",
        "    )):\n",
        "        reduction = len(token) - len(manual)\n",
        "        print(f\"{token:<20} {manual:<20} {pretrained:<20} {reduction:<10}\")\n",
        "\n",
        "    # Enhanced word comparison with football-specific terms\n",
        "    print(\"\\n=== ENHANCED HINDI STEMMER COMPARISON (Football Terms) ===\")\n",
        "    hindi_test_words = [\n",
        "        'बार्सिलोना', 'रियलमैड्रिड', 'लिवरपूल', 'प्रीमियरलीग', 'लालिगा',\n",
        "        'चैंपियंसलीग', 'गोल', 'गोलकीपर', 'डिफेंडर', 'मिडफील्डर',\n",
        "        'फॉरवर्ड', 'कप्तान', 'प्रशिक्षक', 'रेफरी', 'पेनाल्टी',\n",
        "        'फाउल', 'कॉर्नर', 'फ्रीकिक', 'स्टेडियम', 'प्रशंसक',\n",
        "        'ट्रॉफी', 'लीडरबोर्ड', 'स्पर्धा', 'प्रतियोगिता', 'सीजन'\n",
        "    ]\n",
        "\n",
        "    hindi_comparison = processor.compare_stemmers(hindi_test_words, 'hi')\n",
        "    print(f\"Agreement rate: {hindi_comparison['agreement_rate']:.2%}\")\n",
        "    print(f\"Average manual reduction: {hindi_comparison['avg_manual_reduction']:.1f} characters\")\n",
        "    print(f\"Average pretrained reduction: {hindi_comparison['avg_pretrained_reduction']:.1f} characters\")\n",
        "\n",
        "    print(\"\\n=== ENHANCED MARATHI STEMMER COMPARISON (Football Terms) ===\")\n",
        "    marathi_test_words = [\n",
        "        'बार्सिलोना', 'रियलमैड्रिड', 'लिवरपूल', 'प्रीमियरलीग', 'लालिगा',\n",
        "        'चॅम्पियन्सलीग', 'गोल', 'गोलरक्षक', 'डिफेंडर', 'मिडफील्डर',\n",
        "        'फॉरवर्ड', 'कर्णधार', 'प्रशिक्षक', 'रेफरी', 'पेनाल्टी',\n",
        "        'फाउल', 'कॉर्नर', 'फ्रीकिक', 'स्टेडियम', 'प्रेक्षक',\n",
        "        'ट्रॉफी', 'लीडरबोर्ड', 'स्पर्धा', 'स्पर्धात्मक', 'हंगाम'\n",
        "    ]\n",
        "\n",
        "    marathi_comparison = processor.compare_stemmers(marathi_test_words, 'mr')\n",
        "    print(f\"Agreement rate: {marathi_comparison['agreement_rate']:.2%}\")\n",
        "    print(f\"Average manual reduction: {marathi_comparison['avg_manual_reduction']:.1f} characters\")\n",
        "    print(f\"Average pretrained reduction: {marathi_comparison['avg_pretrained_reduction']:.1f} characters\")\n",
        "\n",
        "    # Detailed comparison table with football test words\n",
        "    print(\"\\n=== DETAILED HINDI COMPARISON (Football Terms) ===\")\n",
        "    print(f\"{'Word':<20} {'Manual':<20} {'Pretrained':<20} {'Agreement':<12} {'Reduction':<10}\")\n",
        "    print(\"-\" * 85)\n",
        "    for i, word in enumerate(hindi_test_words):\n",
        "        manual = hindi_comparison['detailed_results']['manual_stem'][i]\n",
        "        pretrained = hindi_comparison['detailed_results']['pretrained_stem'][i]\n",
        "        agreement = \"✓\" if hindi_comparison['detailed_results']['agreement'][i] else \"✗\"\n",
        "        reduction = hindi_comparison['detailed_results']['manual_reduction'][i]\n",
        "        print(f\"{word:<20} {manual:<20} {pretrained:<20} {agreement:<12} {reduction:<10}\")\n",
        "\n",
        "    print(\"\\n=== DETAILED MARATHI COMPARISON (Football Terms) ===\")\n",
        "    print(f\"{'Word':<20} {'Manual':<20} {'Pretrained':<20} {'Agreement':<12} {'Reduction':<10}\")\n",
        "    print(\"-\" * 85)\n",
        "    for i, word in enumerate(marathi_test_words):\n",
        "        manual = marathi_comparison['detailed_results']['manual_stem'][i]\n",
        "        pretrained = marathi_comparison['detailed_results']['pretrained_stem'][i]\n",
        "        agreement = \"✓\" if marathi_comparison['detailed_results']['agreement'][i] else \"✗\"\n",
        "        reduction = marathi_comparison['detailed_results']['manual_reduction'][i]\n",
        "        print(f\"{word:<20} {manual:<20} {pretrained:<20} {agreement:<12} {reduction:<10}\")\n",
        "\n",
        "    # Performance and effectiveness analysis\n",
        "    print(\"\\n=== PERFORMANCE AND EFFECTIVENESS ANALYSIS ===\")\n",
        "    print(\"Manual Rule-Based Stemmer:\")\n",
        "    print(\"  Pros: Fast execution, predictable results, language-specific rules\")\n",
        "    print(\"  Cons: Limited coverage, may over-stem or under-stem\")\n",
        "    print(f\"  Hindi Performance: {hindi_comparison['agreement_rate']:.1%} agreement, {hindi_comparison['avg_manual_reduction']:.1f} avg reduction\")\n",
        "    print(f\"  Marathi Performance: {marathi_comparison['agreement_rate']:.1%} agreement, {marathi_comparison['avg_manual_reduction']:.1f} avg reduction\")\n",
        "\n",
        "    print(\"\\nPretrained Model Stemmer:\")\n",
        "    print(\"  Pros: Better context understanding, handles exceptions well\")\n",
        "    print(\"  Cons: Slower execution, requires training data, may not cover new terms\")\n",
        "    print(f\"  Hindi Performance: {hindi_comparison['avg_pretrained_reduction']:.1f} avg reduction\")\n",
        "    print(f\"  Marathi Performance: {marathi_comparison['avg_pretrained_reduction']:.1f} avg reduction\")\n",
        "\n",
        "    # Recommendation\n",
        "    print(\"\\n=== RECOMMENDATION ===\")\n",
        "    if hindi_comparison['agreement_rate'] > 0.7:\n",
        "        print(\"HIGH AGREEMENT: Both approaches show similar results, manual rules are sufficient\")\n",
        "    elif hindi_comparison['agreement_rate'] > 0.5:\n",
        "        print(\"MODERATE AGREEMENT: Consider hybrid approach combining both methods\")\n",
        "    else:\n",
        "        print(\"LOW AGREEMENT: Pretrained model likely more accurate for complex cases\")\n",
        "\n",
        "    print(f\"For sports news platform: Use manual rules for speed, pretrained for accuracy\")\n",
        "    print(f\"Recommended approach: Hybrid system with manual rules as baseline + pretrained for player/team names\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEoMg4Ghq6zW",
        "outputId": "9706e0af-93fb-487d-fee8-528126443893"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harsh Rawte 22101A0047\n",
            "\n",
            "\n",
            "=== HINDI TEXT PROCESSING (Football Match) ===\n",
            "Original text length: 285 characters\n",
            "Token count: 56\n",
            "First 10 tokens: ['बार्सिलोना', 'और', 'रियल', 'मैड्रिड', 'के', 'बीच', 'एल', 'क्लासिको', 'मैच', 'रविवार']\n",
            "First 10 manual stems: ['बार्सिलो', 'और', 'रियल', 'मैड्रिड', 'के', 'बीच', 'एल', 'क्लासि', 'मैच', 'रविवार']\n",
            "First 10 pretrained stems: ['बार्सिलोना', 'और', 'रियल', 'मैड्रिड', 'के', 'बीच', 'एल', 'क्लासिको', 'मैच', 'रविवार']\n",
            "Tokenization time: 0.0005s\n",
            "Manual stemming time: 0.0027s\n",
            "Pretrained stemming time: 0.0000s\n",
            "\n",
            "=== MARATHI TEXT PROCESSING (Football Match) ===\n",
            "Original text length: 302 characters\n",
            "Token count: 43\n",
            "First 10 tokens: ['बार्सिलोना', 'आणि', 'रियल', 'मैड्रिड', 'यांच्यातील', 'एल', 'क्लासिको', 'सामना', 'रविवारी', 'होणार']\n",
            "First 10 manual stems: ['बार्सिलोना', 'आणि', 'रियल', 'मैड्रिड', 'यांच्यात', 'एल', 'क्लासिको', 'सामना', 'रविवारी', 'होणार']\n",
            "First 10 pretrained stems: ['बार्सिलोना', 'आणि', 'रियल', 'मैड्रिड', 'यांच्यातील', 'एल', 'क्लासिको', 'सामना', 'रविवारी', 'होणार']\n",
            "Tokenization time: 0.0005s\n",
            "Manual stemming time: 0.0025s\n",
            "Pretrained stemming time: 0.0000s\n",
            "\n",
            "=== HINDI VOCABULARY ANALYSIS ===\n",
            "Unique tokens: 45\n",
            "Unique manual stems: 45\n",
            "Unique pretrained stems: 45\n",
            "Vocabulary reduction (manual): 0\n",
            "Vocabulary reduction (pretrained): 0\n",
            "\n",
            "=== MARATHI VOCABULARY ANALYSIS ===\n",
            "Unique tokens: 40\n",
            "Unique manual stems: 40\n",
            "Unique pretrained stems: 40\n",
            "Vocabulary reduction (manual): 0\n",
            "Vocabulary reduction (pretrained): 0\n",
            "\n",
            "=== SAMPLE STEM COMPARISON (Hindi) ===\n",
            "Token                Manual               Pretrained           Reduction \n",
            "---------------------------------------------------------------------------\n",
            "बार्सिलोना           बार्सिलो             बार्सिलोना           2         \n",
            "और                   और                   और                   0         \n",
            "रियल                 रियल                 रियल                 0         \n",
            "मैड्रिड              मैड्रिड              मैड्रिड              0         \n",
            "के                   के                   के                   0         \n",
            "बीच                  बीच                  बीच                  0         \n",
            "एल                   एल                   एल                   0         \n",
            "क्लासिको             क्लासि               क्लासिको             2         \n",
            "मैच                  मैच                  मैच                  0         \n",
            "रविवार               रविवार               रविवार               0         \n",
            "को                   को                   को                   0         \n",
            "होगा                 होगा                 होगा                 0         \n",
            "।                    ।                    ।                    0         \n",
            "दोनों                दोन                  दोनों                2         \n",
            "टीमें                टीम                  टीमें                2         \n",
            "\n",
            "=== SAMPLE STEM COMPARISON (Marathi) ===\n",
            "Token                Manual               Pretrained           Reduction \n",
            "---------------------------------------------------------------------------\n",
            "बार्सिलोना           बार्सिलोना           बार्सिलोना           0         \n",
            "आणि                  आणि                  आणि                  0         \n",
            "रियल                 रियल                 रियल                 0         \n",
            "मैड्रिड              मैड्रिड              मैड्रिड              0         \n",
            "यांच्यातील           यांच्यात             यांच्यातील           2         \n",
            "एल                   एल                   एल                   0         \n",
            "क्लासिको             क्लासिको             क्लासिको             0         \n",
            "सामना                सामना                सामना                0         \n",
            "रविवारी              रविवारी              रविवारी              0         \n",
            "होणार                होणार                होणार                0         \n",
            "आहे                  आहे                  आहे                  0         \n",
            "दोन्ही               दोन्ही               दोन्ही               0         \n",
            "संघ                  संघ                  संघ                  0         \n",
            "ला                   ला                   ला                   0         \n",
            "लीगा                 लीगा                 लीगा                 0         \n",
            "\n",
            "=== ENHANCED HINDI STEMMER COMPARISON (Football Terms) ===\n",
            "Agreement rate: 88.00%\n",
            "Average manual reduction: 0.2 characters\n",
            "Average pretrained reduction: 0.0 characters\n",
            "\n",
            "=== ENHANCED MARATHI STEMMER COMPARISON (Football Terms) ===\n",
            "Agreement rate: 100.00%\n",
            "Average manual reduction: 0.0 characters\n",
            "Average pretrained reduction: 0.0 characters\n",
            "\n",
            "=== DETAILED HINDI COMPARISON (Football Terms) ===\n",
            "Word                 Manual               Pretrained           Agreement    Reduction \n",
            "-------------------------------------------------------------------------------------\n",
            "बार्सिलोना           बार्सिलो             बार्सिलोना           ✗            2         \n",
            "रियलमैड्रिड          रियलमैड्रिड          रियलमैड्रिड          ✓            0         \n",
            "लिवरपूल              लिवरपूल              लिवरपूल              ✓            0         \n",
            "प्रीमियरलीग          प्रीमियरलीग          प्रीमियरलीग          ✓            0         \n",
            "लालिगा               लालिगा               लालिगा               ✓            0         \n",
            "चैंपियंसलीग          चैंपियंसलीग          चैंपियंसलीग          ✓            0         \n",
            "गोल                  गोल                  गोल                  ✓            0         \n",
            "गोलकीपर              गोलकी                गोलकीपर              ✗            2         \n",
            "डिफेंडर              डिफेंडर              डिफेंडर              ✓            0         \n",
            "मिडफील्डर            मिडफील्डर            मिडफील्डर            ✓            0         \n",
            "फॉरवर्ड              फॉरवर्ड              फॉरवर्ड              ✓            0         \n",
            "कप्तान               कप्तान               कप्तान               ✓            0         \n",
            "प्रशिक्षक            प्रशिक्षक            प्रशिक्षक            ✓            0         \n",
            "रेफरी                रेफरी                रेफरी                ✓            0         \n",
            "पेनाल्टी             पेनाल्टी             पेनाल्टी             ✓            0         \n",
            "फाउल                 फाउल                 फाउल                 ✓            0         \n",
            "कॉर्नर               कॉर्नर               कॉर्नर               ✓            0         \n",
            "फ्रीकिक              फ्रीकिक              फ्रीकिक              ✓            0         \n",
            "स्टेडियम             स्टेडियम             स्टेडियम             ✓            0         \n",
            "प्रशंसक              प्रशंसक              प्रशंसक              ✓            0         \n",
            "ट्रॉफी               ट्रॉफी               ट्रॉफी               ✓            0         \n",
            "लीडरबोर्ड            लीडरबोर्ड            लीडरबोर्ड            ✓            0         \n",
            "स्पर्धा              स्पर्धा              स्पर्धा              ✓            0         \n",
            "प्रतियोगिता          प्रतियोगि            प्रतियोगिता          ✗            2         \n",
            "सीजन                 सीजन                 सीजन                 ✓            0         \n",
            "\n",
            "=== DETAILED MARATHI COMPARISON (Football Terms) ===\n",
            "Word                 Manual               Pretrained           Agreement    Reduction \n",
            "-------------------------------------------------------------------------------------\n",
            "बार्सिलोना           बार्सिलोना           बार्सिलोना           ✓            0         \n",
            "रियलमैड्रिड          रियलमैड्रिड          रियलमैड्रिड          ✓            0         \n",
            "लिवरपूल              लिवरपूल              लिवरपूल              ✓            0         \n",
            "प्रीमियरलीग          प्रीमियरलीग          प्रीमियरलीग          ✓            0         \n",
            "लालिगा               लालिगा               लालिगा               ✓            0         \n",
            "चॅम्पियन्सलीग        चॅम्पियन्सलीग        चॅम्पियन्सलीग        ✓            0         \n",
            "गोल                  गोल                  गोल                  ✓            0         \n",
            "गोलरक्षक             गोलरक्षक             गोलरक्षक             ✓            0         \n",
            "डिफेंडर              डिफेंडर              डिफेंडर              ✓            0         \n",
            "मिडफील्डर            मिडफील्डर            मिडफील्डर            ✓            0         \n",
            "फॉरवर्ड              फॉरवर्ड              फॉरवर्ड              ✓            0         \n",
            "कर्णधार              कर्णधार              कर्णधार              ✓            0         \n",
            "प्रशिक्षक            प्रशिक्षक            प्रशिक्षक            ✓            0         \n",
            "रेफरी                रेफरी                रेफरी                ✓            0         \n",
            "पेनाल्टी             पेनाल्टी             पेनाल्टी             ✓            0         \n",
            "फाउल                 फाउल                 फाउल                 ✓            0         \n",
            "कॉर्नर               कॉर्नर               कॉर्नर               ✓            0         \n",
            "फ्रीकिक              फ्रीकिक              फ्रीकिक              ✓            0         \n",
            "स्टेडियम             स्टेडियम             स्टेडियम             ✓            0         \n",
            "प्रेक्षक             प्रेक्षक             प्रेक्षक             ✓            0         \n",
            "ट्रॉफी               ट्रॉफी               ट्रॉफी               ✓            0         \n",
            "लीडरबोर्ड            लीडरबोर्ड            लीडरबोर्ड            ✓            0         \n",
            "स्पर्धा              स्पर्धा              स्पर्धा              ✓            0         \n",
            "स्पर्धात्मक          स्पर्धात्मक          स्पर्धात्मक          ✓            0         \n",
            "हंगाम                हंगाम                हंगाम                ✓            0         \n",
            "\n",
            "=== PERFORMANCE AND EFFECTIVENESS ANALYSIS ===\n",
            "Manual Rule-Based Stemmer:\n",
            "  Pros: Fast execution, predictable results, language-specific rules\n",
            "  Cons: Limited coverage, may over-stem or under-stem\n",
            "  Hindi Performance: 88.0% agreement, 0.2 avg reduction\n",
            "  Marathi Performance: 100.0% agreement, 0.0 avg reduction\n",
            "\n",
            "Pretrained Model Stemmer:\n",
            "  Pros: Better context understanding, handles exceptions well\n",
            "  Cons: Slower execution, requires training data, may not cover new terms\n",
            "  Hindi Performance: 0.0 avg reduction\n",
            "  Marathi Performance: 0.0 avg reduction\n",
            "\n",
            "=== RECOMMENDATION ===\n",
            "HIGH AGREEMENT: Both approaches show similar results, manual rules are sufficient\n",
            "For sports news platform: Use manual rules for speed, pretrained for accuracy\n",
            "Recommended approach: Hybrid system with manual rules as baseline + pretrained for player/team names\n"
          ]
        }
      ]
    }
  ]
}